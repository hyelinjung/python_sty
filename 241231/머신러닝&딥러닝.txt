머신러닝 : 데이터를 기반으로 패턴을 인식하는 기술은 맞지만 새로운 데이터를 만들어가는 것
이라고 설명하기보다 기존 데이터를 바탕으로 예측,분류,회귀 등 특정 작업을 수행하는 모델을 학습하는 것.
딥러닝 : 머신러닝의 하위 분야...복잡한 데이터에서 더 깊은 패턴을 추출


※새로운 데이터로 예측 -공부6시간 과외2시간
print(f'\n예측 점수:{prediction[0]:.1f}')

->인덱스 첫 번째 요소를 가져온 후 소수점 1자리로 반올림하여 실수 형식으로 출력 ex)3.456 ->3.5 출력

※회귀 계수(coef_) : 선형 회귀 모델에서 각 독립 변수에 대한 기울기를 나타냄 즉,
 독립 변수가 종속 변수에 미치는 영향을 나타낸다.
->model.coef_[0]이라는 말은 model.coef_[0]가 [1.0,1.0]이라면 1.0이된다. 즉
첫 번째 특성(예를 들어 x의 첫 번째 열이 1,2,3,4일때) 대한 회귀 계수가 1.0임을 말한다.
=> 첫 번째 측성의 값이 1증가할때마다 y의 값도 1증가

※회귀 모델의 기본 형태 y= a*X +b

※X_train, X_test, y_train, y_test 
= train_test_split(X,y,test_size=0.2,random_state=42)처럼 
train_test_split을 사용해 훈련셋과 테스트 셋을 생성하는 이유

->주 이유는 모델의 성능을 파악하고 과적합을 방지하기 위해서 데이터를 나눈다.
->훈련데이터로만 모델을 평가하면 '과적합'의 위험이 있다..즉 모델이 훈련 데이터에 지나티게 적합하여 새로운 데이터에 대한 예측 성능이 떨어지는 현상
X : features데이터, 즉 독립변수들이 담긴 데이터셋
y : target 데이터, 즉 종속 변수
->x와y를 랜덤하게 분할해 비율0.2에 맞게 훈련데이터와 테스트데이터를 나누고 이결과를 4개의 변수에 할당
X_train : 훈련 데이터에 해당하는 특성 값들
y_train : 훈련 데이터에 대한 목표 값
X_test : 테스트 데이터에 해당하는 특성값
y_test : 테스트 데이터에 대한 목표 값

※ model.predict([5]) 실행 시 "ValueError: Expected 2D array, got 1D array instead: array=[5]"발생
->model.fit()은 인자로 2D배열을 기대한다.
->model.predict([5]) VS model.predict([[5]])
후자는 2D배열로 1개의 샘플,1개의 특성(5)을 가진 데이터 / 전자는 샘플 개수 없이 하나의 특성값만 가진 1D배열

※model.fit()인자에 들어가는 훈련데이터
->해당 메서드를 사용해 훈련데이터로 모델의 파라미터(가중치,계수)를 조정
->모델은 훈련데이털르 기반으로 학습해 패턴이나 관계를 가지고 이를 기반으로 예측을 할수 있도록 한다.
(흐름)모델은 X_train에 특성과 y_train에서 제공된 목표값을 비교하면서 학습... 이 과정에서 모델은 파라미터를 조정,훈련 데이터에서 나타나는 관계를
잘 표현할 수 있게 한다.

※sns.barplot()에서 x축,y축을 독립,종속 변수라고 생각
->그 와는 별개로, 데이터 시각화를 위한 축으로 사용된다. x축과 y축 값은 그래프를 그리는 목적에 따라 지정된다.
x축 :그래프에서 수치형 데이터 ,특성의 중요도 같은 연속적인 값을 나타냄
y축 :범주형 데이터 또는 특성 이름과 같은 순서가 없는 항목을 나타냄

※classifier.predict([[6]]) 처럼 모델로 예측을 할 때 인자값 의미
->데이터셋의 인덱스가 아니라,예측하고자 하는 데이터 포인트의 특성 값,
즉 해당 모델에 값 6을 가진 새로운 데이터 포인트를 입력해 그에 대한 예측값을 반환
->결과값 array([0], dtype=int64)

※TfidfVectorizer의 fit_transform()
->벡터화 작업(텍스트 데이터를 수치 데이터로 변환)과 TF-IDF 가중치 계산이 함께 이뤄지는 과정
[동작의 흐름]
1.텍스트를 토큰화 -> 텍스트를 단어 단위로 분리
2.모든 텍스트 데이터에서 고유한 단어(특징)을 추출하고 ,각 단어에 고유한 인덱스를 부여한다
3.각 문서에 대해 단어의 빈도(TF)를 계산하고, 단어의 중요도를 조정하기 위해 IDF값을 곱한다
->단순히 단어의 빈도수를 확인하기 위해서가 아니라, 텍스트 데이터를 백터화하고 각 단어의 중요도를 계산하기 위해서
->왜? 학습모델이 사용할수 있는 텍스트가 아니라 수치 데이터로 변환해야 해서


※경사하강법 : 주로 머신러닝 모델의 손실함수를 최소화하기 위해 사용된다
즉,모델이 예측한 값 y, 실제값y_ 간의 차이(손실)를 최소화하는 최적의 파라미터를 찾는 것

※절편 model.intercept
-> 선형 회귀 모델에서 절편은 회귀 직선이 y축과 만나는 점을 의미한다.
->절편은 모든 피쳐 값들이 모두 0일때 모델이 예측하는 출력값. 즉 예측값의 기본 수준을 나타낸다.

※r2_score()와 LinearRegression.score()의 차이
전자)실제값과 예측값을 구해서 입력. 후자)입력데이터(X_test)와 실제값을 제공하면 R2값을 제공